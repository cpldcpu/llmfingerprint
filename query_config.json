{
  "llms": [
    {
      "name": "qwq-32b-preview",
      "model": "qwen/qwq-32b-preview",
      "temperature": 0.7,
      "top_p": 0.9,
      "repetition_penalty": 1
    },
    {
      "name": "mistral-large-2411",
      "model": "mistralai/mistral-large-2411",
      "temperature": 0.7,
      "top_p": 0.9,
      "repetition_penalty": 1
    },
    {
      "name": "command-r7b-12-2024",
      "model": "cohere/command-r7b-12-2024",
      "temperature": 0.7,
      "top_p": 0.9,
      "repetition_penalty": 1
    },
    {
      "name": "deepseek-chat-v2.5",
      "model": "deepseek/deepseek-chat-v2.5",
      "temperature": 0.7,
      "top_p": 0.9,
      "repetition_penalty": 1
    },
    {
      "name": "nova-lite-v13",
      "model": "amazon/nova-lite-v1",
      "temperature": 0.7,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "DeepSeek-V3",
      "model": "deepseek/deepseek-chat",
      "temperature": 0.7,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "grok-2-1212",
      "model": "x-ai/grok-2-1212",
      "temperature": 0.7,
      "top_p": 0.95,
      "repetition_penalty": 1
  },
  {
    "name": "gpt-4o-2024-11-20",
    "model": "openai/gpt-4o-2024-11-20",
    "temperature": 0.7,
    "top_p": 1.0,
    "repetition_penalty": 1
  },
  {
    "name": "llama-3.3-70b-instruct",
    "model": "meta-llama/llama-3.3-70b-instruct",
    "max_tokens": 2000,
    "temperature": 0.8,
    "top_p": 1.0,
    "repetition_penalty": 1
  },
  
    {
      "name": "llama-3.1-8B-instruct",
      "model": "meta-llama/llama-3.1-8b-instruct",
      "temperature": 0.9,
      "top_p": 1,
      "frequency_penalty": 0,
      "presence_penalty": 0,
      "repetition_penalty": 1,
      "top_k": 0
    },
    {
      "name": "hermes-3-llama-3.1-405",
      "model": "nousresearch/hermes-3-llama-3.1-405b",
      "temperature": 1.0,
      "top_p": 1,
      "repetition_penalty": 1
    },
    {
      "name": "claude-3.5-sonnet",
      "model": "anthropic/claude-3.5-sonnet",
      "temperature": 0.9,
      "top_p": 0.9,
      "repetition_penalty": 1
    },
    {
      "name": "gpt-4o-mini",
      "model": "openai/gpt-4o-mini",
      "temperature": 0.7,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "gpt-4o",
      "model": "openai/gpt-4o",
      "temperature": 0.7,
      "top_p": 1.0,
      "repetition_penalty": 1
    },    
    {
      "name": "gemini-flash-1.5",
      "model": "google/gemini-flash-1.5",
      "temperature": 0.7,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "gemini-pro-1.5",
      "model": "google/gemini-pro-1.5",
      "temperature": 1,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "phi-3-medium-128k-instruct",
      "model": "microsoft/phi-3-medium-128k-instruct",
      "temperature": 0.7,
      "top_p": 1,
      "repetition_penalty": 1
    },
    {
      "name": "mistral-7b-instruct",
      "model": "mistralai/mistral-7b-instruct",
      "temperature": 0.88,
      "top_p": 1,
      "repetition_penalty": 1
    },
    {
      "name": "llama-3.1-405b-instruct",
      "model": "meta-llama/llama-3.1-405b-instruct",
      "max_tokens": 2000,
      "temperature": 0.9,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "llama-3.1-70b-instruct",
      "model": "meta-llama/llama-3.1-70b-instruct",
      "max_tokens": 2000,
      "temperature": 0.9,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "llama-3.2-3b-instruct",
      "model": "meta-llama/llama-3.2-3b-instruct",
      "max_tokens": 2000,
      "temperature": 1.0,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "wizardlm-2-8x22b",
      "model": "microsoft/wizardlm-2-8x22b",
      "max_tokens": 2000,
      "temperature": 1.0,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "mixtral-8x22b-instruct",
      "model": "mistralai/mixtral-8x22b-instruct",
      "max_tokens": 2000,
      "temperature": 1.0,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "qwen-2.5-72b-instruct",
      "model": "qwen/qwen-2.5-72b-instruct",
      "max_tokens": 2000,
      "temperature": 1.0,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "mythomax-l2-13b",
      "model": "gryphe/mythomax-l2-13b:free",
      "max_tokens": 2000,
      "temperature": 1.0,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "claude-3-haiku",
      "model": "anthropic/claude-3-haiku",
      "temperature": 1.0,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "claude-3-opus",
      "model": "anthropic/claude-3-opus",
      "temperature": 0.9,
      "top_p": 1.0,
      "repetition_penalty": 1
    },    
    {
      "name": "o1-mini",
      "model": "openai/o1-mini",
      "temperature": 1.0,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "mistral-7b-instruct-v0.3",
      "model": "mistralai/mistral-7b-instruct-v0.3",
      "temperature": 0.30,
      "top_p": 1,
      "repetition_penalty": 1
    },
    {
      "name": "llama-3.2-1b-instruct",
      "model": "meta-llama/llama-3.2-1b-instruct",
      "max_tokens": 2000,
      "temperature": 1.0,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "deepseek-r1",
      "model": "deepseek/deepseek-reasoner",
      "max_tokens": 16000,
      "temperature": 1.0,
      "top_p": 1.0,
      "repetition_penalty": 1
    }
  ]
}
